{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing of the LLM Generated Data:\n",
    "\n",
    "After [running the LLM model](./restaurant_extractor.ipynb) to generate restaurant recommendations, the data is post-processed to clean and filter the results. The post-processing steps are outlined below.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Load JSON Files**:\n",
    "    - Reads all JSON files from the `results` directory, which follow the naming pattern `recs_*.json`.\n",
    "    - Combines the data from these files into a single list.\n",
    "\n",
    "2. **Remove Duplicates**:\n",
    "    - Identifies and removes duplicate entries based on the `restaurant_name` field to ensure each restaurant is unique.\n",
    "\n",
    "3. **Clean Data**:\n",
    "    - Removes entries with missing or invalid `restaurant_name` or `address`.\n",
    "    - Filters out restaurants whose `restaurant_name` starts with \"Infatuation\".\n",
    "    - Corrects improperly formatted `cuisine` fields.\n",
    "\n",
    "4. **Filter by Southern California**:\n",
    "    - Uses the Ollama API to determine if the restaurant's `address` is located in Southern California.\n",
    "    - Removes entries that are not located in Southern California.\n",
    "\n",
    "5. **Update Location Tags**:\n",
    "    - Analyzes the `location_tags` field to remove tags that are neighborhoods in Southern California.\n",
    "    - Verifies the `address` of each entry to determine the neighborhood it resides in.\n",
    "    - Updates the `location_tags` to include the neighborhood name if it is not already present.\n",
    "\n",
    "6. **Save Cleaned Data**:\n",
    "    - Writes the processed and cleaned data to a new JSON file `combined_recs.json` in the `results` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def load_json_files(directory):\n",
    "    files = glob.glob(os.path.join(directory, 'recs_*.json'))\n",
    "    data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data.extend(json.load(f))\n",
    "    return data\n",
    "\n",
    "# Function to remove duplicates from the data based on restaurant name\n",
    "def remove_duplicates(data):\n",
    "    unique_restaurants = {}\n",
    "    for entry in data:\n",
    "        restaurant_name = entry.get('restaurant_name', '')\n",
    "        if restaurant_name:\n",
    "            restaurant_name = restaurant_name.strip()\n",
    "            if restaurant_name and restaurant_name not in unique_restaurants:\n",
    "                unique_restaurants[restaurant_name] = entry\n",
    "    return list(unique_restaurants.values())\n",
    "\n",
    "# Function to clean data by removing entries with missing restaurant names, addresses, or invalid cuisine data\n",
    "def clean_data(data):\n",
    "    cleaned_data = []\n",
    "    for entry in data:\n",
    "        restaurant_name = entry.get('restaurant_name', '').strip() if entry.get('restaurant_name') else ''\n",
    "        address = entry.get('address', '').strip() if entry.get('address') else ''\n",
    "        if not restaurant_name or restaurant_name.startswith(\"Infatuation\"):\n",
    "            continue\n",
    "        if address.startswith(\"123\"):\n",
    "            continue\n",
    "        if 'cuisine' in entry and isinstance(entry['cuisine'], str):\n",
    "            try:\n",
    "                entry['cuisine'] = json.loads(entry['cuisine'])\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        cleaned_data.append(entry)\n",
    "    return cleaned_data\n",
    "\n",
    "# Function to filter data based on Southern California\n",
    "def filter_southern_california(data):\n",
    "    filtered_data = []\n",
    "    for entry in data:\n",
    "        address = entry.get('address', '').strip()\n",
    "        if is_in_southern_california(address):\n",
    "            filtered_data.append(entry)\n",
    "    return filtered_data\n",
    "\n",
    "# Function to determine if an address is in Southern California\n",
    "def is_in_southern_california(address):\n",
    "    global ollama\n",
    "    prompt = f\"Is the following address located in Southern California?\\n\\nAddress: {address}\\n\\nAnswer with 'Yes' or 'No'.\"\n",
    "    response = ollama(prompt)\n",
    "    return \"Yes\" in response\n",
    "    \n",
    "# Function to determine if a tag is a neighborhood in Southern California\n",
    "def is_neighborhood_in_socal(tag):\n",
    "    prompt = f\"Is '{tag}' a neighborhood in Southern California? Answer with 'Yes' or 'No'.\"\n",
    "    response = ollama(prompt)\n",
    "    return \"Yes\" in response\n",
    "\n",
    "# Function to determine the neighborhood of an address\n",
    "def get_neighborhood_from_address(address):\n",
    "    prompt = f\"What neighborhood is the following address located in?\\n\\nAddress: {address}\\n\\nProvide the neighborhood name ONLY.\"\n",
    "    response = ollama(prompt)\n",
    "    return response.strip()\n",
    "\n",
    "# Function to update the location tags of the data\n",
    "def update_location_tags(data):\n",
    "    updated_data = []\n",
    "    for entry in data:\n",
    "        location_tags = entry.get('location_tag', [])\n",
    "        address = entry.get('address', '').strip()\n",
    "\n",
    "        # Remove tags that are neighborhoods in Southern California\n",
    "        location_tags = [tag for tag in location_tags if not is_neighborhood_in_socal(tag)]\n",
    "\n",
    "        # Get the neighborhood of the address\n",
    "        neighborhood = get_neighborhood_from_address(address)\n",
    "\n",
    "        # If the neighborhood is not in the updated location_tags, add it\n",
    "        if neighborhood and neighborhood not in location_tags:\n",
    "            location_tags.append(neighborhood)\n",
    "\n",
    "        # Update the entry\n",
    "        entry['location_tag'] = location_tags\n",
    "        updated_data.append(entry)\n",
    "    return updated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'results'\n",
    "combined_data = load_json_files(directory)\n",
    "combined_data = remove_duplicates(combined_data)\n",
    "combined_data = clean_data(combined_data)\n",
    "\n",
    "# Initialize the Ollama model\n",
    "ollama = Ollama(model=\"llama3:8b-instruct-q5_0\")\n",
    "combined_data = filter_southern_california(combined_data)\n",
    "combined_data = update_location_tags(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(directory, 'combined_recs.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
